{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imported-shark",
   "metadata": {},
   "source": [
    "Using this as a resource: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "administrative-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_codons(dna_seq):\n",
    "    codons = []\n",
    "    for i in range(0, len(dna_seq), 3):\n",
    "        codons.append(dna_seq[i:i+3])\n",
    "    return codons\n",
    "assert get_list_of_codons('ATGCCCGGGAAATTTTAG') == ['ATG', 'CCC', 'GGG', 'AAA', 'TTT', 'TAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_proteins = []\n",
    "host_codons = []\n",
    "\n",
    "u_aas = set()\n",
    "u_codons = set()\n",
    "all_codons = []\n",
    "initial_states = []\n",
    "emissions = {}\n",
    "for record in SeqIO.parse('GCF_000009045.1_ASM904v1_genomic.gbff', \"genbank\"):\n",
    "    for feature in record.features:\n",
    "        if feature.type == 'CDS' and 'translation' in feature.qualifiers:\n",
    "            protein = feature.qualifiers['translation'][0] + '*'\n",
    "            host_proteins.append(protein)\n",
    "            \n",
    "            aas = set([aa for aa in protein])\n",
    "            codon = get_list_of_codons(str(feature.extract(record.seq)))\n",
    "            \n",
    "            host_codons.append(codon)\n",
    "            all_codons.append(codon)\n",
    "            initial_states.append(codon[0])\n",
    "            u_aas = u_aas.union(aas)\n",
    "            u_codons = u_codons.union(set(codon))\n",
    "            for i, cdn in enumerate(codon):\n",
    "                emissions[cdn] = protein[i]\n",
    "lu_aas = ['0'] + list(u_aas)\n",
    "lu_codons = ['PAD'] + list(u_codons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sized-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(seq_obj, seqtype='dna'):\n",
    "    encdr = lu_codons\n",
    "    symbols = get_list_of_codons(seq_obj)\n",
    "    if seqtype != 'dna':\n",
    "        encdr = lu_aas\n",
    "        symbols = [c for c in seq_obj]\n",
    "    outseq = np.array([encdr.index(s) for s in symbols])\n",
    "    return outseq\n",
    "\n",
    "test_aa = 'MENILD0'\n",
    "test_nuc = 'AAAAAAATAAGATAGPAD'\n",
    "assert encode_seq(test_aa, seqtype='prot')[0] == lu_aas.index(test_aa[0]) and \\\n",
    "       encode_seq(test_aa, seqtype='prot')[-1] == lu_aas.index(test_aa[-1])\n",
    "assert encode_seq(test_nuc, seqtype='dna')[0] == lu_codons.index(test_nuc[0:3]) and \\\n",
    "       encode_seq(test_nuc, seqtype='dna')[-1] == lu_codons.index(test_nuc[-3:])\n",
    "\n",
    "def decode_seq(num_array, seqtype='dna'):\n",
    "    encdr = lu_codons\n",
    "    if seqtype != 'dna':\n",
    "        encdr = lu_aas\n",
    "    outseq = [encdr[s] for s in num_array]\n",
    "    return ''.join(outseq)\n",
    "\n",
    "assert decode_seq(encode_seq(test_nuc)) == test_nuc\n",
    "assert decode_seq(encode_seq(test_aa, seqtype='prot'), seqtype='prot') == test_aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-burns",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "balanced-cooling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Think of the sequences as one hot vectors stacked up, so that the dimensions are (seq_len, num_characters)\n",
    "# Given a dictionary of characters of length 300, we'll pad and pack 3 sequences together of lengths 25, 22, and 15\n",
    "a = torch.ones(25, 300)\n",
    "b = torch.ones(22, 300)\n",
    "c = torch.ones(15, 300)\n",
    "d = pad_sequence([a, b, c])\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brazilian-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "class ProteinsSet(Dataset):\n",
    "    \"\"\"Protein data set\"\"\"\n",
    "    \n",
    "    def __init__(self, list_of_proteins, list_of_codons, codon_list, aa_list):\n",
    "        self.prot_collection = list_of_proteins\n",
    "        self.codon_collection = list_of_codons\n",
    "        self.lu_codons = codon_list\n",
    "        self.lu_aas = aa_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.prot_collection)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        encd_prot = self.__encode__(self.prot_collection[idx], 'prot')\n",
    "        encd_codn = self.__encode__(self.codon_collection[idx], 'dna')\n",
    "        return (encd_prot, encd_codn)\n",
    "    \n",
    "    def __encode__(self, seq_obj, seqtype):\n",
    "        encdr = self.lu_codons\n",
    "        symbols = seq_obj\n",
    "        if seqtype != 'dna':\n",
    "            encdr = self.lu_aas\n",
    "            symbols = [c for c in seq_obj]\n",
    "        encoded_seq = []\n",
    "        t = torch.zeros(len(symbols), len(encdr))\n",
    "        for i, s in enumerate(symbols):\n",
    "            t[i, encdr.index(s)] = 1\n",
    "        return t\n",
    "\n",
    "def pad_collate(batch):\n",
    "    # turn list of tuples into two lists: https://stackoverflow.com/a/8081590 \n",
    "    [xx, yy] = map(list, zip(*batch))\n",
    "    print(xx[0].shape)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "    xx_pad = pad_sequence(xx, batch_first=False, padding_value=0)\n",
    "    yy_pad = pad_sequence(yy, batch_first=False, padding_value=0)\n",
    "    print([xx_pad.size()])\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "ps = ProteinsSet(host_proteins, host_codons, lu_codons, lu_aas)\n",
    "batch_size = 16\n",
    "data_loader = DataLoader(dataset=ps, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "objective-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([210, 22])\n",
      "[torch.Size([519, 16, 22])]\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "curious-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_dim = max(batch[2]) #expect xx_pad to be (max(x_lens), 16, 22)\n",
    "assert batch[0].size()[0] == ex_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaning-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why pack? https://stackoverflow.com/a/56211056\n",
    "embedding_dim = len(lu_aas)\n",
    "h_dim = 100\n",
    "n_layers = 2\n",
    "x_embed = batch[0]\n",
    "x_lens = batch[2]\n",
    "rnn = nn.GRU(embedding_dim, h_dim, n_layers, batch_first=False)\n",
    "\n",
    "x_packed = pack_padded_sequence(x_embed, x_lens, batch_first=False, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(n_layers, batch_size, h_dim)\n",
    "output_packed, h1 = rnn(x_packed, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unusual-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_padded, output_lengths = pad_packed_sequence(output_packed, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opposed-arlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([519, 16, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_padded.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
